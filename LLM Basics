# ğŸ“˜ Notes: AI & LLM Basics

---

## ğŸ”¹ Learning Goals
- Learn tokens  
- Understand prompting strategies  
- Why LLMs hallucinate  
- How LangChain fits into AI application development  

---

## ğŸ› ï¸ Mini Project
- **Prompt-only Q&A Bot**  

---

## ğŸ¯ Topics Breakdown

### 1. Learn Tokens

#### Conceptual Overview
| Concept | Simple Explanation | Example |
|---------|--------------------|---------|
| **Token** | A small chunk of text that an LLM reads | Words, sub-words, or characters |
| **Why important** | LLMs donâ€™t read sentences directly â†’ they break text into tokens first | `"ChatGPT is great!"` â†’ `[ "Chat", "G", "PT", " is", " great", "!" ]` |
| **Tokenization** | Process of splitting text into tokens | Different models tokenize differently (GPT vs BERT vs LLaMA) |
| **Token limit** | Maximum number of tokens per model (context window) | GPT-4o: ~128k tokens |
| **Token cost** | APIs charge per 1k tokens (input + output) | 1 token â‰ˆ 4 chars â†’ 1k tokens â‰ˆ 750 words |

#### How Tokenization Works
| Section | Step / Point | Example / Note |
|---------|--------------|----------------|
| **Input text** | `"Rajinikanth is the superstar!"` | - |
| **Tokenizer splits** | `["Raj", "ini", "kanth", " is", " the", " superstar", "!"]` | - |
| **Model processes tokens** | Converts into IDs (numbers) | - |
| **Generation** | Predicts next token until stopping | - |

#### Why Tokens Matter
| Aspect | Key Point |
|--------|-----------|
| **Prompt length** | You canâ€™t exceed the modelâ€™s context window |
| **Cost** | More tokens = higher API bill |
| **Control** | Explains weird splits (e.g., `"playing"` â†’ `["play", "ing"]`) |
| **Streaming** | Models generate one token at a time |

#### Advanced Considerations
| Topic | Key Point | Why It Matters |
|-------|-----------|----------------|
| **Granularity** | Tokens are not always full words (sub-words, chars) | `"playing"` â†’ `["play", "ing"]` |
| **Languages** | Some languages (Chinese, Tamil) require more tokens | Higher cost, context usage |
| **Whitespace & punctuation** | Spaces, commas, periods are tokens | Formatting increases cost |
| **Context Window** | Input + output tokens together count toward limit | 8k model: 7.5k input â†’ only 500 output |
| **Truncation** | Longer than context â†’ older tokens dropped | Risk of losing info |
| **Compression tricks** | Use shorter wording to save tokens | Reduces cost, frees space |
| **Embeddings** | Tokenization applies to embeddings too | Critical for RAG apps |
| **Streaming** | One token at a time | Enables real-time output |
| **Pricing** | Per 1k tokens (input + output separately) | Essential for cost planning |

---

### 2. Prompting Strategies

#### Core Strategies
| Strategy | Explanation | Example Prompt | Expected Behavior |
|----------|-------------|----------------|------------------|
| **Zero-shot** | Ask directly without examples | *â€œTranslate â€˜How are you?â€™ to French.â€* | Model uses pre-trained knowledge |
| **Few-shot** | Provide examples to guide | *â€œTranslate: â€˜Good morningâ€™ â†’ â€˜Bonjourâ€™; â€˜Thank youâ€™ â†’ â€˜Merciâ€™. Now: â€˜How are you?â€™â€* | Model follows pattern |
| **Chain-of-thought (CoT)** | Force reasoning step-by-step | *â€œIf 3 apples, eat 1, how many left? Think step by step.â€* | Explains reasoning â†’ final answer |

#### Applied to Data Science
| Strategy | Explanation | Example Prompt | Expected Behavior |
|----------|-------------|----------------|------------------|
| **Zero-shot** | Direct classification | *â€œClassify: â€˜The product was amazing!â€™â€* | *Positive* |
| **Few-shot** | Guided classification | *â€œI love this â†’ Positive; Worst experience â†’ Negative; Now: â€˜Not bad, but could be betterâ€™â€* | *Neutral* |
| **Chain-of-thought** | Step-by-step reasoning | *â€œStore sold 120 shoes, 1/3 sneakers. How many sandals?â€* | *Explains: 40 sneakers, 80 sandals* |
| **Zero-shot + CoT** | Direct with reasoning | *â€œSummarize this dataset step by step before a 2-line summaryâ€* | Outline â†’ Summary |
| **Few-shot + CoT** | Examples + reasoning | *â€œConvert English to SQL: â€˜Count usersâ€™ â†’ SELECT COUNT(*) FROM customers; Now: â€˜Get total revenue.â€™ Think step by step.â€* | SQL with reasoning |

---

### 3. Why LLMs Hallucinate

| Cause | Explanation | Example | Data Science Angle |
|-------|-------------|---------|--------------------|
| **Limits of training data** | Only â€œknowsâ€ patterns from training | Asked about 2025 dataset â†’ makes it up | Like classifier on biased data |
| **Lack of grounding** | No fact-checking | Invents fake research title | Predictions without real-time DB |
| **Ambiguous prompts** | Vague â†’ model guesses | â€œTell me about Pythonâ€ â†’ language/animal | Bad feature engineering |
| **Overconfidence** | Doesnâ€™t show uncertainty | Wrong SQL confidently | Regression w/o error bars |
| **No reasoning verification** | Skips steps | Wrong math result | Pipeline errors w/o validation |

---

### 4. Controlling Hallucinations

| Method | Explanation | Example | DS Angle |
|--------|-------------|---------|----------|
| **RAG** | Add external knowledge (docs, DBs, APIs) | *â€œSummarize this PDFâ€* â†’ pulls from doc | Like feature augmentation |
| **Prompt engineering** | Write clear, unambiguous prompts | *â€œExplain Python (language) in 3 pointsâ€* | Like feature engineering |
| **Output validation** | Enforce structured formats | *Return JSON {â€œnameâ€: str, â€œyearâ€: int}* | Schema validation |
| **Chain-of-thought (CoT)** | Force step-by-step reasoning | *â€œ56 Ã· 8 Ã— 2. Show steps.â€* | Logging intermediate steps |
| **Human-in-the-loop** | Human review for critical tasks | Analyst checks summary | Manual label validation |
| **Fine-tuning / domain adaptation** | Train on domain data | Medical bot trained on clinical notes | Transfer learning |
| **Confidence estimation** | Add thresholds/fallbacks | *If similarity < threshold â†’ say â€˜I donâ€™t knowâ€™* | Probability thresholds |

---

## ğŸ“Œ Summary
- **Tokens** = basic units of LLM processing (affect cost, performance, context).  
- **Prompting strategies** = zero-shot, few-shot, chain-of-thought, hybrids.  
- **Hallucinations** = caused by data limits, lack of grounding, ambiguity, overconfidence.  
- **Control hallucinations** = use RAG, better prompts, validation, reasoning, human checks, and fine-tuning.  

---
